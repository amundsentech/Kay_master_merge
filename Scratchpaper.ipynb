{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cleaningtools as ct \n",
    "import file_config as fconfig\n",
    "import merge_config as config\n",
    "import assay_sample_config as aconfig\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('/Volumes/GoogleDrive/Shared drives/AMC Projects/_AZ_Kay/_Master Databases/drill assay samples master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'([a-zA-Z]{2}\\\\-{1}\\\\d{2}\\\\-{1}\\\\d{2})'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aconfig.hole_id_formats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan]\n",
      "[nan]\n",
      "[nan]\n",
      "[nan 'KM-20-14A' 'KM-20-10C' 'KM-20-10B' 'KM-20-10A' 'KM-20-03A'\n",
      " 'KM-22-71A' 'KM-22-63D' 'KM-22-62C' 'KM-22-62B' 'KM-22-59A' 'KM-22-57C']\n",
      "Can only use .str accessor with string values!\n",
      "Can only use .str accessor with string values!\n",
      "Can only use .str accessor with string values!\n",
      "[nan]\n",
      "[nan]\n",
      "Can only use .str accessor with string values!\n",
      "[nan]\n",
      "Can only use .str accessor with string values!\n",
      "[nan]\n",
      "[nan 'KM-20-14A' 'KM-20-10C' 'KM-20-10B' 'KM-20-10A' 'KM-20-03A'\n",
      " 'KM-22-71A' 'KM-22-63D' 'KM-22-62C' 'KM-22-62B' 'KM-22-59A' 'KM-22-57C']\n",
      "[nan 'KM-22-71A' 'KM-22-63D' 'KM-22-62C' 'KM-22-62B' 'KM-22-59A'\n",
      " 'KM-22-57C']\n",
      "['KM-21-19K']\n",
      "Can only use .str accessor with string values!\n",
      "Can only use .str accessor with string values!\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    try:\n",
    "        print(data[col].str.extract(aconfig.hole_id_formats[1]).squeeze().unique())\n",
    "    except Exception as e: \n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_for_merge(data):\n",
    "    for col in data.columns:\n",
    "        if 'depth_ft'in col.lower():\n",
    "            data['from_ft']=data[col]\n",
    "            data['to_ft']=data['from_ft'].shift(-1)-1\n",
    "            #convert ft to meters\n",
    "            data['from_m']=data['from_ft']* .3281\n",
    "            data['to_m']=data['to_ft'] * .3281\n",
    "            data=data.drop(data.filter(like='Depth').columns,axis=1)\n",
    "        if ('hole' in col.lower())& ('id' in col.lower()):\n",
    "            data[col]=data[col].astype(object)\n",
    "            data.rename(columns={f'{col}':f'hole_id'},inplace=True)\n",
    "        try: \n",
    "            data[col]=data[col].str.strip()\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            #print(f'{col}: {e}')\n",
    "        data.rename(columns={f'{col}':f'{col.strip().lower()}'},inplace=True)\n",
    "        data=data.drop(data.filter(like='unnamed'),axis=1)\n",
    "        if 'from_ft'in col.lower():\n",
    "            try:\n",
    "                drop_index=data[data['from_ft'].isna()].index\n",
    "                data=data.drop(drop_index,axis=0)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "                #print(f'{e}')\n",
    "    if 'hole_id' not in data.columns:\n",
    "        data['hole_id']=np.nan\n",
    "    if 'recvd wt.'  in data.columns:\n",
    "        try:\n",
    "            data['recvd wt.']=pd.to_numeric(data['recvd wt.'],errors='coerce')\n",
    "            data['from_ft']=pd.to_numeric(data['from_ft'],errors='coerce')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    names=data.loc[:,data.columns.duplicated()].columns\n",
    "    if len(names)>0:\n",
    "        print(f'duplcated column: {names} drop or else the nasty merge bug')\n",
    "        data=data.loc[:,~data.columns.duplicated()].copy()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_concat_onid(big_df,data,merge_col=['geo','sample_id','hole_id','from_ft','to_ft']):\n",
    "    \n",
    "    num_common=big_df[big_df.sample_id.isin(data.sample_id)].shape[0]\n",
    "    print(f'{num_common} common ids, concat')\n",
    "\n",
    "    \n",
    "    if num_common==0:\n",
    "        print(f'{num_common} common ids, concat')\n",
    "        big_df=pd.concat([big_df,data],axis=0)\n",
    "    else: \n",
    "        print (f'{num_common} common ids, merge')\n",
    "        big_df=big_df.merge(data,on=merge_col,how='left')\n",
    "    n_col=big_df.shape[1]\n",
    "    print('duplicate columns: ', big_df.columns.duplicated().sum())\n",
    "    print('duplicate indexs: ', big_df.index.duplicated().sum())\n",
    "    print(f'{n_col} columns')\n",
    "    return big_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df=pd.DataFrame()\n",
    "data_list=[]\n",
    "prev_cols=[]\n",
    "for file in config.merge_samples:\n",
    "    print(f\"####### merge: {file.split('/')[-1]} #######\")\n",
    "    data=pd.read_csv(file)\n",
    "    data=clean_for_merge(data)\n",
    "    data_list.append(data)\n",
    "    data=data.astype(object)\n",
    "    big_df=big_df.astype(object)\n",
    "    big_cols=list(big_df.columns)\n",
    "    small_cols=list(data.columns)\n",
    "    \n",
    "    dups=sorted([col for col in big_cols if col in small_cols])\n",
    "    \n",
    "    try:\n",
    "        [dups.remove(x) for x in ['file','folder','start_depth','end_depth']if x in data.columns]\n",
    "    except:\n",
    "        pass\n",
    "    print(f'common columns {dups}')\n",
    "\n",
    "\n",
    "    \n",
    "    big_index=list(big_df.index)\n",
    "    small_index=list(data.index)\n",
    "    \n",
    "    same_ids= [id for id in big_index if id in small_index]\n",
    "    n_ids=len(same_ids)\n",
    "    if n_ids==0:\n",
    "        print(f'{n_ids} common ids concat')\n",
    "        big_df=pd.concat([big_df,data],axis=0,join='outer')\n",
    "    else:\n",
    "        print(f'{n_ids} common ids merge')\n",
    "        big_df=big_df.merge(data,on=dups,how='outer')\n",
    "    print(f'data shape {big_df.shape}')\n",
    "cols=config.main_columns\n",
    "not_dups=[i for i in big_df.columns if i not in cols]\n",
    "big_df=pd.concat([big_df[cols],big_df[not_dups]],axis=1).set_index('sample_id')\n",
    "big_df.sort_index(inplace=True)\n",
    "#big_df=big_df.groupby(['sample_id']).apply(lambda x: x.fillna(method='ffill').fillna(method='bfill').drop_duplicates(keep='first')).droplevel(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.to_excel('all_sampleid_test.xlsx')\n",
    "big_df.to_excel('/Volumes/GoogleDrive/Shared drives/AMC Projects/_AZ_Kay/_Master Databases/all_sampleid_test.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df=pd.read_excel('all_sampleid_test.xlsx')\n",
    "big_df[['from_ft','to_ft']]=big_df[['from_ft','to_ft']].fillna(0)\n",
    "big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lith=pd.read_csv(fconfig.lith_file)\n",
    "lith=clean_for_merge(lith)\n",
    "lith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_cols=['sample_id','hole_id','from_ft','to_ft']\n",
    "other_cols=[col for col in big_df.columns if col not in merge_cols]\n",
    "zipped=zip(big_df['sample_id'],big_df['hole_id'], big_df['from_ft'], big_df['to_ft'])\n",
    "depths=pd.DataFrame([(s_id,h_id, y) for s_id,h_id, start, end in zipped for y in np.arange(start, end,.5)],\n",
    "                   columns=['sample_id','hole_id','depth'])\n",
    "depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths=depths.merge(big_df,on='sample_id',validate='1:m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged=depths.merge(lith,left_on=['hole_id','depth'],right_on=['hole_id','from_ft'],how='outer')\n",
    "other_cols=[col for col in depths if col not in merge_cols+'depths']\n",
    "merged=pd.concat([merged[merge_cols+'depth'],merged[other_cols]],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_excel('merged_test.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
