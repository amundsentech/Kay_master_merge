{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check for pandas\n",
      "pandas is properly installed\n",
      "check for tqdm\n",
      "tqdm is properly installed\n",
      "check for numpy\n",
      "numpy is properly installed\n",
      "check for openpyxl\n",
      "openpyxl is properly installed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cleaningtools as ct \n",
    "import file_config as fconfig\n",
    "import merge_config as config\n",
    "import assay_sample_config as aconfig\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "tqdm.pandas()\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import file_config as fconfig\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_for_merge(data):\n",
    "    for col in data.columns:\n",
    "        if 'depth_ft'in col.lower():\n",
    "            try:\n",
    "                data[col]=pd.to_numeric(data[col],errors='coerce')\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            data['from_ft']=data[col]\n",
    "            data['to_ft']=data['from_ft'].shift(-1)-.5\n",
    "            #convert ft to meters\n",
    "            data['from_m']=data['from_ft']* .3281\n",
    "            data['to_m']=data['to_ft'] * .3281\n",
    "            data=data.drop(data.filter(like='Depth').columns,axis=1)\n",
    "        if ('hole' in col.lower())& ('id' in col.lower()):\n",
    "            data[col]=data[col].astype(object)\n",
    "            data.rename(columns={f'{col}':f'hole_id'},inplace=True)\n",
    "        try: \n",
    "            data[col]=data[col].str.strip()\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            #print(f'{col}: {e}')\n",
    "        data.rename(columns={f'{col}':f'{col.strip().lower()}'},inplace=True)\n",
    "        data=data.drop(data.filter(like='unnamed'),axis=1)\n",
    "        if 'from_ft'in col.lower():\n",
    "            try:\n",
    "                drop_index=data[data['from_ft'].isna()].index\n",
    "                data=data.drop(drop_index,axis=0)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "                #print(f'{e}')\n",
    "    if 'hole_id' not in data.columns:\n",
    "        data['hole_id']=np.nan\n",
    "    if 'recvd wt.'  in data.columns:\n",
    "        try:\n",
    "            data['recvd wt.']=pd.to_numeric(data['recvd wt.'],errors='coerce')\n",
    "            data['from_ft']=pd.to_numeric(data['from_ft'],errors='coerce')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    names=data.loc[:,data.columns.duplicated()].columns\n",
    "    if len(names)>0:\n",
    "        print(f'duplcated column: {names} drop or else the nasty merge bug')\n",
    "        data=data.loc[:,~data.columns.duplicated()].copy()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_merge_groups(data):\n",
    "    data=data.fillna(method='ffill')\n",
    "    data=data.fillna(method='bfill')\n",
    "    data=data.drop_duplicates(keep='first')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_depths(data):\n",
    "    data[['from_ft','to_ft']]=data[['from_ft','to_ft']].fillna(0)\n",
    "    if 'sample_id' in data.columns:\n",
    "        zipped=zip(data['sample_id'],data['hole_id'], data['from_ft'], data['to_ft'])\n",
    "        depths=pd.DataFrame([(s_id,h_id, y) for s_id,h_id, start, end in zipped for y in np.arange(start, end,.5)],\n",
    "                    columns=['sample_id','hole_id','true_depth'])\n",
    "        d_frame=depths.merge(data,on=['sample_id','hole_id'])\n",
    "        d_frame=depths.merge(data,on=['sample_id','hole_id'])\n",
    "    else:\n",
    "        data['START']=data['from_ft']\n",
    "        zipped=zip(data['START'],data['hole_id'], data['from_ft'], data['to_ft'])\n",
    "        depths=pd.DataFrame([(s,h_id, y) for s,h_id, start, end in zipped for y in np.arange(start, end,.5)],\n",
    "                        columns=['START','hole_id','true_depth'])\n",
    "        d_frame=depths.merge(data,on=['START','hole_id'])\n",
    "        d_frame=d_frame.drop('START',axis=1)\n",
    "    d_frame=d_frame.drop(d_frame.filter(like='from').columns,axis=1)\n",
    "    d_frame=d_frame.drop(d_frame.filter(like='to').columns,axis=1)\n",
    "    return d_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_start_end(data):\n",
    "    depths=data['true_depth']\n",
    "    start=depths.values[0]\n",
    "    end=depths.values[-1]\n",
    "    data['from_ft']=start\n",
    "    data['to_ft']=end\n",
    "    data=data.drop_duplicates(subset=['from_ft','to_ft'],keep='first')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read alteration master\n",
      "clean alteration master\n",
      "alteration master does not have sample ids\n",
      "explode alteration master\n",
      "read mineralization master\n",
      "clean mineralization master\n",
      "duplcated column: Index(['min_type'], dtype='object') drop or else the nasty merge bug\n",
      "mineralization master does not have sample ids\n",
      "explode mineralization master\n",
      "read hyp-package samples master\n",
      "clean hyp-package samples master\n",
      "hyp-package samples master has sample ids\n",
      "read structure master\n",
      "clean structure master\n",
      "structure master does not have sample ids\n",
      "explode structure master\n",
      "read drill assay samples master\n",
      "clean drill assay samples master\n",
      "drill assay samples master has sample ids\n",
      "read drill assays master\n",
      "clean drill assays master\n",
      "'from_ft'\n",
      "drill assays master has sample ids\n",
      "read lithology master\n",
      "clean lithology master\n",
      "lithology master does not have sample ids\n",
      "explode lithology master\n",
      "read spectral master\n",
      "clean spectral master\n",
      "'from_ft'\n",
      "duplcated column: Index(['spectrumid'], dtype='object') drop or else the nasty merge bug\n",
      "spectral master has sample ids\n",
      "read xrf samples master\n",
      "clean xrf samples master\n",
      "xrf samples master does not have sample ids\n",
      "explode xrf samples master\n"
     ]
    }
   ],
   "source": [
    "hole_list=[]\n",
    "sample_list=[]\n",
    "sample_data_names=[]\n",
    "hole_data_names=[]\n",
    "files=[file for file in os.listdir(fconfig.output_path) if file.endswith('.csv')]\n",
    "for file in files:\n",
    "    name=file.split('.')[0]\n",
    "    if len(name)==0:\n",
    "        continue\n",
    "    print(f'read {name}')\n",
    "    try:\n",
    "        data=pd.read_csv(fconfig.output_path+file,low_memory=False,on_bad_lines='skip')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('likely not a csv')\n",
    "        continue\n",
    "    print(f'clean {name}')\n",
    "    data=clean_for_merge(data)\n",
    "\n",
    "    if 'sample_id' in data.columns:\n",
    "        print(f'{name} has sample ids')\n",
    "        sample_list.append(data)\n",
    "        sample_data_names.append(name)\n",
    "    else:\n",
    "        print(f'{name} does not have sample ids')\n",
    "        print(f'explode {name}')\n",
    "        try:\n",
    "            data=explode_depths(data)\n",
    "            hole_list.append(data)\n",
    "            hole_data_names.append(name)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('must have (depths and hole ids) or (sample_ids) to merge into master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the data in each group. holes and samples\n",
    "def merge_dflist(data_list,data_names):\n",
    "    big_df=pd.DataFrame()\n",
    "    non_id_cols=['true_depth', 'hole_id']\n",
    "    for i,data in enumerate(data_list):\n",
    "        ## merge all the data with sample_ids\n",
    "        name=data_names[i]\n",
    "        suf=name.split(' ')[0]\n",
    "        print(f\"####### merge frame {i}: {name} suffix= {suf} #######\")\n",
    "        data=data.astype(object)\n",
    "        big_df=big_df.astype(object)\n",
    "        big_cols=list(big_df.columns)\n",
    "        small_cols=list(data.columns)\n",
    "        \n",
    "        dups=sorted([col for col in big_cols if col in small_cols])\n",
    "        cols=config.main_columns\n",
    "        try:\n",
    "            [dups.remove(x) for x in ['file','folder','start_depth','end_depth']if x in data.columns]\n",
    "        except:\n",
    "            pass\n",
    "        if 'sample_id' not in data.columns:\n",
    "            cols=non_id_cols\n",
    "            try:\n",
    "                big_index=list(big_df.hole_id.unique())\n",
    "                small_index=list(data.hole_id.unique())\n",
    "                same_ids= [id for id in big_index if id in small_index]\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                same_ids=[]\n",
    "            dups=non_id_cols\n",
    "        else:\n",
    "            big_index=list(big_df.index)\n",
    "            small_index=list(data.index)\n",
    "            same_ids= [id for id in big_index if id in small_index]\n",
    "        print(f'common columns {dups}')\n",
    "        n_ids=len(same_ids)\n",
    "        if n_ids==0:\n",
    "            print(f'{n_ids} common ids concat')\n",
    "            big_df=pd.concat([big_df,data],axis=0,join='outer')\n",
    "        else:\n",
    "            print(f'{n_ids} common ids merge')\n",
    "            big_df=big_df.merge(data,on=dups,suffixes=[None,'_'+suf],how='outer')\n",
    "\n",
    "        print(f'data shape {big_df.shape}')\n",
    "    \n",
    "    not_dups=[i for i in big_df.columns if i not in cols]\n",
    "    big_final=pd.concat([big_df[cols],big_df[not_dups]],axis=1)\n",
    "\n",
    "    big_final.drop(big_final.filter(like='file').columns,axis=1,inplace=True)\n",
    "    big_final.drop(big_final.filter(like='folder').columns,axis=1,inplace=True)\n",
    "    big_final.sort_index(inplace=True)\n",
    "    return big_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### merge frame 0: hyp-package samples master suffix= hyp-package #######\n",
      "common columns []\n",
      "0 common ids concat\n",
      "data shape (1080, 9)\n",
      "####### merge frame 1: drill assay samples master suffix= drill #######\n",
      "common columns ['from_ft', 'from_m', 'geo', 'hole_id', 'sample_id', 'to_ft', 'to_m']\n",
      "1077 common ids merge\n",
      "data shape (2671, 18)\n",
      "####### merge frame 2: drill assays master suffix= drill #######\n",
      "common columns ['hole_id', 'sample_id']\n",
      "2671 common ids merge\n",
      "data shape (8082, 78)\n",
      "####### merge frame 3: spectral master suffix= spectral #######\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:916: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  key_col = Index(lvals).where(~mask_left, rvals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common columns ['hole_id', 'recvd wt.', 'sample_id']\n",
      "8044 common ids merge\n",
      "data shape (15648, 201)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:916: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  key_col = Index(lvals).where(~mask_left, rvals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED MERGING SAMPLES\n",
      "####### merge frame 0: alteration master suffix= alteration #######\n",
      "'DataFrame' object has no attribute 'hole_id'\n",
      "common columns ['true_depth', 'hole_id']\n",
      "0 common ids concat\n",
      "data shape (109179, 13)\n",
      "####### merge frame 1: mineralization master suffix= mineralization #######\n",
      "common columns ['true_depth', 'hole_id']\n",
      "62 common ids merge\n",
      "data shape (118186, 24)\n",
      "####### merge frame 2: structure master suffix= structure #######\n",
      "common columns ['true_depth', 'hole_id']\n",
      "82 common ids merge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:916: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  key_col = Index(lvals).where(~mask_left, rvals)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:916: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  key_col = Index(lvals).where(~mask_left, rvals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape (145555, 32)\n",
      "####### merge frame 3: lithology master suffix= lithology #######\n",
      "common columns ['true_depth', 'hole_id']\n",
      "89 common ids merge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:916: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  key_col = Index(lvals).where(~mask_left, rvals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape (360906, 40)\n",
      "####### merge frame 4: xrf samples master suffix= xrf #######\n",
      "common columns ['true_depth', 'hole_id']\n",
      "6 common ids merge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:916: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  key_col = Index(lvals).where(~mask_left, rvals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape (375690, 138)\n"
     ]
    }
   ],
   "source": [
    "big_samples=merge_dflist(sample_list,sample_data_names)\n",
    "print('FINISHED MERGING SAMPLES')\n",
    "big_holes=merge_dflist(hole_list,hole_data_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=big_samples\n",
    "def list_fill(data,column,id):\n",
    "    data=data[data[column]==id].fillna(method='ffill').fillna(method='bfill').drop_duplicates(keep='first')\n",
    "    return data.copy()\n",
    "def fast_fill_merge(data,column,desc):\n",
    "    dup_id=list(data[data[column].notna().duplicated()][column].unique())\n",
    "    data_list=[list_fill(data,column,id) for id in tqdm(dup_id,desc=desc)]\n",
    "    print('done listing')\n",
    "    data=pd.concat(data_list,axis=0)\n",
    "    print('done with concat')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_start_end(data,column,id):\n",
    "    data=data[data[column]==id]\n",
    "    depths=data['true_depth']\n",
    "    data=data.drop('true_depth',axis=1)\n",
    "    data=data.drop_duplicates(keep='first')\n",
    "    start=depths.values[0]\n",
    "    end=depths.values[-1]\n",
    "    data['from_ft']=start\n",
    "    data['to_ft']=end\n",
    "    data=data.drop_duplicates(keep='first').copy()\n",
    "    return data\n",
    "    \n",
    "def fast_pull_ends(data,column,desc):\n",
    "    dup_id=list(data[data[column].notna().duplicated()][column].unique())\n",
    "    data_list=[list_start_end(data,column,id) for id in tqdm(dup_id,desc='pulling from/too depths:')]\n",
    "    print('done listing data with ends')\n",
    "    data=pd.concat(data_list,axis=0)\n",
    "    print('done with concat')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####clean the sample_ids#########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clean_samples: 100%|██████████| 9376/9376 [03:37<00:00, 43.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done listing\n",
      "done with concat\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo</th>\n",
       "      <th>hole_id</th>\n",
       "      <th>from_ft</th>\n",
       "      <th>to_ft</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>from_m</th>\n",
       "      <th>to_m</th>\n",
       "      <th>work_order</th>\n",
       "      <th>qaqc</th>\n",
       "      <th>description</th>\n",
       "      <th>...</th>\n",
       "      <th>d_ep1550</th>\n",
       "      <th>wav_h2o</th>\n",
       "      <th>d_h2o</th>\n",
       "      <th>feslope</th>\n",
       "      <th>int_feoxide</th>\n",
       "      <th>wav_feoxide</th>\n",
       "      <th>d_feoxide</th>\n",
       "      <th>fintfeoxide</th>\n",
       "      <th>start_depth_spectral</th>\n",
       "      <th>end_depth_spectral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JR</td>\n",
       "      <td>KM-22-77</td>\n",
       "      <td>710.0</td>\n",
       "      <td>719.5</td>\n",
       "      <td>G452078</td>\n",
       "      <td>232.951</td>\n",
       "      <td>236.06795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JR</td>\n",
       "      <td>KM-22-77</td>\n",
       "      <td>720.0</td>\n",
       "      <td>729.5</td>\n",
       "      <td>G452079</td>\n",
       "      <td>236.232</td>\n",
       "      <td>239.34895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JR</td>\n",
       "      <td>KM-22-77</td>\n",
       "      <td>730.0</td>\n",
       "      <td>739.5</td>\n",
       "      <td>G452080</td>\n",
       "      <td>239.513</td>\n",
       "      <td>242.62995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JR</td>\n",
       "      <td>KM-22-77</td>\n",
       "      <td>740.0</td>\n",
       "      <td>749.5</td>\n",
       "      <td>G452081</td>\n",
       "      <td>242.794</td>\n",
       "      <td>245.91095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JR</td>\n",
       "      <td>KM-22-77</td>\n",
       "      <td>750.0</td>\n",
       "      <td>759.5</td>\n",
       "      <td>G452082</td>\n",
       "      <td>246.075</td>\n",
       "      <td>249.19195</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15643</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W999995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1907.390</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>1.1473</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15644</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W999996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1908.160</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>1.0490</td>\n",
       "      <td>0.9356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15645</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W999997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1908.918</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>1.2944</td>\n",
       "      <td>1.0150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15646</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W999998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1908.000</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>1.2451</td>\n",
       "      <td>1.0486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15647</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W999999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000.361</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>1.2813</td>\n",
       "      <td>0.8308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9594 rows × 193 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       geo   hole_id  from_ft  to_ft sample_id   from_m       to_m work_order  \\\n",
       "1       JR  KM-22-77    710.0  719.5   G452078  232.951  236.06795        NaN   \n",
       "2       JR  KM-22-77    720.0  729.5   G452079  236.232  239.34895        NaN   \n",
       "3       JR  KM-22-77    730.0  739.5   G452080  239.513  242.62995        NaN   \n",
       "4       JR  KM-22-77    740.0  749.5   G452081  242.794  245.91095        NaN   \n",
       "5       JR  KM-22-77    750.0  759.5   G452082  246.075  249.19195        NaN   \n",
       "...    ...       ...      ...    ...       ...      ...        ...        ...   \n",
       "15643  NaN       NaN      NaN    NaN   W999995      NaN        NaN        NaN   \n",
       "15644  NaN       NaN      NaN    NaN   W999996      NaN        NaN        NaN   \n",
       "15645  NaN       NaN      NaN    NaN   W999997      NaN        NaN        NaN   \n",
       "15646  NaN       NaN      NaN    NaN   W999998      NaN        NaN        NaN   \n",
       "15647  NaN       NaN      NaN    NaN   W999999      NaN        NaN        NaN   \n",
       "\n",
       "       qaqc description  ...  d_ep1550   wav_h2o   d_h2o  feslope  \\\n",
       "1       NaN         NaN  ...       NaN       NaN     NaN      NaN   \n",
       "2       NaN         NaN  ...       NaN       NaN     NaN      NaN   \n",
       "3       NaN         NaN  ...       NaN       NaN     NaN      NaN   \n",
       "4       NaN         NaN  ...       NaN       NaN     NaN      NaN   \n",
       "5       NaN         NaN  ...       NaN       NaN     NaN      NaN   \n",
       "...     ...         ...  ...       ...       ...     ...      ...   \n",
       "15643   NaN         NaN  ...       NaN  1907.390  0.0150   1.1473   \n",
       "15644   NaN         NaN  ...       NaN  1908.160  0.0117   1.0490   \n",
       "15645   NaN         NaN  ...       NaN  1908.918  0.0140   1.2944   \n",
       "15646   NaN         NaN  ...       NaN  1908.000  0.0158   1.2451   \n",
       "15647   NaN         NaN  ...       NaN  2000.361  0.0346   1.2813   \n",
       "\n",
       "       int_feoxide wav_feoxide  d_feoxide  fintfeoxide  start_depth_spectral  \\\n",
       "1              NaN         NaN        NaN          NaN                   NaN   \n",
       "2              NaN         NaN        NaN          NaN                   NaN   \n",
       "3              NaN         NaN        NaN          NaN                   NaN   \n",
       "4              NaN         NaN        NaN          NaN                   NaN   \n",
       "5              NaN         NaN        NaN          NaN                   NaN   \n",
       "...            ...         ...        ...          ...                   ...   \n",
       "15643       0.9576         NaN        NaN          NaN                  94.0   \n",
       "15644       0.9356         NaN        NaN          NaN                  95.0   \n",
       "15645       1.0150         NaN        NaN          NaN                  96.0   \n",
       "15646       1.0486         NaN        NaN          NaN                  97.0   \n",
       "15647       0.8308         NaN        NaN          NaN                  98.0   \n",
       "\n",
       "       end_depth_spectral  \n",
       "1                     NaN  \n",
       "2                     NaN  \n",
       "3                     NaN  \n",
       "4                     NaN  \n",
       "5                     NaN  \n",
       "...                   ...  \n",
       "15643                95.0  \n",
       "15644                96.0  \n",
       "15645                97.0  \n",
       "15646                98.0  \n",
       "15647                99.0  \n",
       "\n",
       "[9594 rows x 193 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('#####clean the sample_ids#########')\n",
    "big_samples=fast_fill_merge(data,column='sample_id',desc='clean_samples')\n",
    "big_samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####explode sample_ids#########\n",
      "######### merge holes and samples ##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:916: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  key_col = Index(lvals).where(~mask_left, rvals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### fill the final_data ##########\n"
     ]
    }
   ],
   "source": [
    "print('#####explode sample_ids#########')\n",
    "samp_ex=explode_depths(big_samples)\n",
    "print('######### merge holes and samples ##########')\n",
    "merged=samp_ex.merge(big_holes,on=['hole_id','true_depth'],how='outer')\n",
    "print('######### fill the final_data ##########')\n",
    "merged['u_id']=merged.fillna(np.inf).groupby(['hole_id','true_depth']).ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clean total_data:   0%|          | 688/338393 [00:18<2:41:22, 34.88it/s]"
     ]
    }
   ],
   "source": [
    "merged_test=fast_fill_merge(merged,column='u_id',desc='clean total_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test['u_id']=merged_test.fillna(np.inf).groupby(merged_test.drop('true_depth',axis=1).columns.to_list()).ngroup()\n",
    "merged_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test=fast_pull_ends(merged_test,column='u_id')\n",
    "final_cols=['sample_id','hole_id','from_ft','to_ft']\n",
    "des_cols = merged_test.filter(like='description').columns\n",
    "other_cols= [col for col in merged_test.columns if col not in final_cols]\n",
    "merged_test=pd.concat([merged_test[final_cols],merged_test[des_cols],merged_test[other_cols]],axis=1)\n",
    "merged_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['u_id']=merged.fillna(np.inf).groupby(merged.drop('true_depth',axis=1).columns.to_list()).ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_test=fast_pull_ends(merged,column='u_id',desc='pull start ends')\n",
    "final_cols=['sample_id','hole_id','from_ft','to_ft']\n",
    "des_cols = merged_test.filter(like='description').columns\n",
    "other_cols= [col for col in merged_test.columns if col not in final_cols]\n",
    "merged_test=pd.concat([merged_test[final_cols],merged_test[des_cols],merged_test[other_cols]],axis=1)\n",
    "merged_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['u_id']=merged.fillna(np.inf).groupby(merged.drop('true_depth',axis=1).columns.to_list()).ngroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['from_ft']=np.inf\n",
    "merged['to_ft']=np.inf\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test=merged.groupby(merged['u_id']).progress_apply(pull_start_end).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test.drop('true_depth',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols=['sample_id','hole_id','from_ft','to_ft']\n",
    "des_cols = merged_test.filter(like='description').columns\n",
    "other_cols= [col for col in merged_test.columns if col not in final_cols]\n",
    "merged_test=pd.concat([merged_test[final_cols],merged_test[des_cols],merged_test[other_cols]],axis=1)\n",
    "merged_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test=merged_test.T.drop_duplicates(keep='first').T\n",
    "merged_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for col in merged_test.columns:\n",
    "    if merged_test[col].isna().sum()==len(merged_test):\n",
    "        print(f'drop {col}: no data')\n",
    "        merged_test=merged_test.drop(col,axis=1)\n",
    "merged_test=merged_test.sort_values(by=['sample_id','hole_id','from_ft'],ascending=False)\n",
    "merged_test=merged_test.set_index('sample_id')\n",
    "merged_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_test.to_excel('/Volumes/GoogleDrive/Shared drives/AMC Projects/_AZ_Kay/_Master Databases/master_MASTER.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
